{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Databricks Demo Notebook\n",
    "This notebook demonstrates how to access IDB data hosted on databricks through the `msk_cdm` python package (via Databricks Python SDK)\n",
    "\n",
    "\n",
    "## Setup\n",
    "After creating your conda environment including the `msk_cdm` package (See [README](https://github.com/clinical-data-mining/msk_cdm/blob/main/README.md)), the user will need to collect (3) connection details from the Databricks UI, and create an API token. These are the items to collect:\n",
    "- API Token\n",
    "- Server Hostname\n",
    "- HTTP Path\n",
    "- Host URL (Typically a https extension of Server Hostname)\n",
    "\n",
    "### Finding the connection details\n",
    "- [Finding the connection details to Databricks](https://docs.databricks.com/en/integrations/compute-details.html)\n",
    "- [Creating a token](https://docs.databricks.com/en/dev-tools/auth/pat.html)\n",
    "\n",
    "## The 'msk_cdm' Databricks module\n",
    "The Databricks module can be instantiated by this import function:\n",
    "```\n",
    "from msk_cdm.databricks import DatabricksAPI\n",
    "\n",
    "obj_dbk = DatabricksAPI(    \n",
    "    TOKEN=token,\n",
    "    URL=url,\n",
    "    HTTP_PATH=http_path,\n",
    "    HOSTNAME=hostname\n",
    ")\n",
    "```\n",
    "\n",
    "\n",
    "### Creating a Databricks environment file \n",
    "If the user would like to store connection details in a file and instantiating through the file instead of individual connection details, the user can create a file with this template:\n",
    "\n",
    "`<pathname>/env_databricks.txt`:\n",
    "```\n",
    "TOKEN=<YOUR_TOKEN>\n",
    "URL=<THE_URL>\n",
    "HOSTNAME=<THE_HOSTNAME>\n",
    "HTTP_PATH=<THE_HTTP_PATH>\n",
    "```\n",
    "\n",
    "Then, instantiate in Python with\n",
    "```\n",
    "f = '<pathname>/env_databricks.txt'\n",
    "obj_dbk = DatabricksAPI(fname_databricks_env=f)\n",
    "```\n",
    "\n",
    "---"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "95888251e5f9c572"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from msk_cdm.databricks import DatabricksAPI"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "e3514c37f39760a8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "token = '<YOUR_TOKEN>'\n",
    "url = '<THE_URL'\n",
    "hostname = '<THE_HOSTNAME>'\n",
    "http_path = '<THE_HTTP_PATH>'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b1e939bdbd581597",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Instantiate the Databricks Object"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aa7ade39d4b6eb71"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Try with the individual connection details"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea627548fe00701a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "obj_dbk = DatabricksAPI(\n",
    "    token=token,\n",
    "    http_path=http_path,\n",
    "    hostname=hostname\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "88a20cc312675d9e",
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Attempt the same with the environment file\n",
    " "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5a4df53e3b9d7447"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "fname_env = 'databricks_env.txt'\n",
    "obj_dbk = DatabricksAPI(fname_databricks_env=fname_env)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b7371e1198615b4e",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define some Spark SQL to make a Query "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "437923c36a05b045"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "sql = f\"\"\"\n",
    "USE CATALOG mode_clinical_test;\n",
    "\n",
    "SELECT DISTINCT\n",
    "    t1.pt_mrn AS MRN,\n",
    "    t1.pt_birth_dte AS PT_BIRTH_DTE,\n",
    "    t1.pt_death_dte AS PT_DEATH_DTE,\n",
    "    t1.pt_mrn_create_dte AS MRN_CREATE_DTE,\n",
    "    t1.pt_sex_desc AS GENDER,\n",
    "    t1.pt_marital_sts_desc AS MARITAL_STATUS,\n",
    "    t1.pt_religion_desc AS RELIGION,\n",
    "    t1.pt_race_desc AS RACE,\n",
    "    t4.core_ethnicity_desc AS ETHNICITY,\n",
    "    t6.pla_last_contact_dte AS PLA_LAST_CONTACT_DTE,\n",
    "    t6.pla_last_actv_dte AS PLA_LAST_ACTV_DTE,\n",
    "    t6.pla_last_adm_dte AS PLA_LAST_ADM_DTE,\n",
    "    t6.pla_last_dsch_dte AS PLA_LAST_DSCH_DTE,\n",
    "    t6.pla_last_appt_dte AS PLA_LAST_APPT_DTE,\n",
    "    t6.pla_last_drvst_dte AS PLA_LAST_DRVST_DTE,\n",
    "    t6.pla_last_tx_dte AS PLA_LAST_TX_DTE,\n",
    "    t6.pla_last_chemo_dte AS PLA_LAST_CHEMO_DTE,\n",
    "    t6.pla_last_surg_dte AS PLA_LAST_SURG_DTE,\n",
    "    t6.pla_last_rt_dte AS PLA_LAST_RT_DTE,\n",
    "    CASE\n",
    "        WHEN DATEDIFF(COALESCE(t1.pt_death_dte, CURRENT_DATE()), t1.pt_birth_dte) / 365.25 < 90 THEN\n",
    "            CAST(DATEDIFF(COALESCE(t1.pt_death_dte, CURRENT_DATE()), t1.pt_birth_dte) / 365.25 AS INT)\n",
    "        ELSE\n",
    "            89\n",
    "        END AS CURRENT_AGE_DEID\n",
    "FROM\n",
    "    dcmspt.patient_demographics_v t1\n",
    "        INNER JOIN dcmspt.patient_latest_activity t6 ON t1.pt_pt_deidentification_id = t6.pla_pt_deidentification_id\n",
    "        LEFT JOIN dcmspt.patient_core_demographics t4 ON t1.pt_pt_deidentification_id = t4.core_pt_deidentification_id\n",
    "\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "64f7b515ab1c8b32",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Run the Query!"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff04e4d051d571c3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df = obj_dbk.query_from_sql(sql=sql)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c17bf7b19183a9dd",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.head();"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a2d8014c04d08151",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Close connection with Databricks\n",
    "When complete with queries. We may get emails from Databricks maintainers if connections aren't closed."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e35b1db9495a9a75"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "obj_dbk.close_connection()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c7c947d1ef59396"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "conda-env-cdm",
   "language": "python",
   "display_name": "conda-env-cdm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
