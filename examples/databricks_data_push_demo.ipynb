{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Databricks Test Notebook for Data Storage and Table Creation\n",
    "\n",
    "### Finding the connection details\n",
    "- [Finding the connection details to Databricks](https://docs.databricks.com/en/integrations/compute-details.html)\n",
    "- [Creating a token](https://docs.databricks.com/en/dev-tools/auth/pat.html)\n",
    "- [Using OAUTH when using a Service Principal](https://docs.databricks.com/en/dev-tools/auth/oauth-m2m.html)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "95888251e5f9c572"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from msk_cdm.minio import MinioAPI\n",
    "from msk_cdm.databricks import DatabricksAPI\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## User configurations\n",
    "- Databricks connection configuration\n",
    "- Minio connection configuration\n",
    "- Location of data on Minio\n",
    "- Location of data to be written on Databricks volume\n",
    "- Table specifications for data written on volume"
   ],
   "id": "44b77e278a68c0db"
  },
  {
   "cell_type": "code",
   "source": [
    "# Databricks configurations\n",
    "overwrite = True\n",
    "fname_databricks_config = '/gpfs/mindphidata/cdm_repos/databricks_env_test_group.txt'\n",
    "catalog = 'cbioportal_test'\n",
    "schema = 'cdm_test'\n",
    "volume = 'cdm_write_volume'\n",
    "\n",
    "# Minio Configuratios\n",
    "fname_minio_config = '/gpfs/mindphidata/fongc2/minio_env.txt'\n",
    "file_minio = 'demographics/ddp_demographics.tsv'\n",
    "sep = '\\t'\n",
    "\n",
    "dir_volume = os.path.join('/Volumes',catalog,schema,volume)\n",
    "fname_save_databricks = os.path.join(dir_volume, file_minio)\n",
    "table = Path(file_minio).stem\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d7df077a34a8fe98",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Create dictionary to convert your dataframe object into a Spark SQL Table",
   "id": "3055fef61c02a1b0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dict_database_table_info = {\n",
    "    'catalog': catalog,\n",
    "    'schema': schema,\n",
    "    'volume_path': fname_save_databricks,\n",
    "    'table': table,\n",
    "    'sep': sep\n",
    "}"
   ],
   "id": "f1e320e5ca352561",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## Get Data from MinIO as an Example",
   "metadata": {
    "collapsed": false
   },
   "id": "fb63474a4d0ef1b0"
  },
  {
   "cell_type": "code",
   "source": [
    "obj_minio = MinioAPI(fname_minio_env=fname_minio_config)\n",
    "obj = obj_minio.load_obj(path_object=file_minio)\n",
    "df = pd.read_csv(obj, sep='\\t')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "59f27af42de977fa",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "df.head();",
   "metadata": {
    "collapsed": false
   },
   "id": "fe5231b2b670fe11",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Write Dataframe into Databricks\n",
    "### Instantiate Databricks API module"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5dc4a5668f12ec65"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "obj_db = DatabricksAPI(fname_databricks_env=fname_databricks_config)\n",
    "\n",
    "\n"
   ],
   "id": "d7952b8591077203",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Write data to volume and create table in two separate steps\n",
    "This demonstrates the data can be written to the volume, and then as an option at a later point, can be exposed as a table"
   ],
   "id": "70c7b1abf009616d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "obj_db.write_db_obj(\n",
    "    df=df,\n",
    "    volume_path=fname_save_databricks,\n",
    "    sep=sep,\n",
    "    overwrite=overwrite\n",
    ")"
   ],
   "id": "eb2b9070f53e239a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Now that object is created, a table can be created for Spark SQL use\n",
    "obj_db.create_table_from_volume(\n",
    "    dict_database_table_info=dict_database_table_info\n",
    ")"
   ],
   "id": "86c11923d68afa99",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Do the same, but in one step\n",
    "This step is preferable for creating pipeline, insuring that a table and ojbect on volume are always in sync\n"
   ],
   "id": "b5e3a3936638395a"
  },
  {
   "metadata": {
    "collapsed": false
   },
   "cell_type": "code",
   "source": [
    "obj_db.write_db_obj(\n",
    "    df=df, \n",
    "    volume_path=fname_save_databricks,\n",
    "    sep=sep,\n",
    "    overwrite=overwrite,\n",
    "    dict_database_table_info=dict_database_table_info\n",
    ")"
   ],
   "id": "7c5ab8fbfc47d9a4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "6cf3d94ed66521e",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Query the data just uploaded to Databricks\n",
    "### Using SQL \n",
    "Analogous to Dremio"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "92d40e3947ea41a6"
  },
  {
   "cell_type": "code",
   "source": [
    "g = f\"\"\"select  * from {catalog}.{schema}.{table}\"\"\"\n",
    "g"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b49fda34757e3d8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_demo_sql = obj_db.query_from_sql(sql=g)",
   "id": "fd44066b72c1ddb1",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "df_demo_sql.describe()",
   "metadata": {
    "collapsed": false
   },
   "id": "b04823a101b12337",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Using the volume download process \n",
    "Analogous to MinIO"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c6ff21677e45660b"
  },
  {
   "cell_type": "code",
   "source": [
    "# read/download\n",
    "df_demo_vol = obj_db.read_db_obj(volume_path=fname_save_databricks, sep='\\t')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cb20b7f33a72d4f",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "df_demo_vol.head()",
   "metadata": {
    "collapsed": false
   },
   "id": "ee60eca38d1a967b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "f896ce0abba8f70b",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "conda-env-cdm-fongc2",
   "language": "python",
   "display_name": "conda-env-cdm-fongc2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
